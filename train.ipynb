{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYiMs6OSUezc",
        "outputId": "06196d63-3173-43a1-852e-9b0f934b90d1"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create and save the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313,
          "referenced_widgets": [
            "3d16f1796bec4646817748c4f6ced833",
            "67417eda9a724c46a5644fbdb13f5351",
            "8857202e6e4d4630a9d1cfb4860e2b57",
            "a012e717318f452fbb4c613f81d480a6",
            "db0b2e2cfd4a42b8946de1cb971f575b",
            "b42b9e0cf8054f18933240dcfa3dea21",
            "adb4836c7d7c4260aff58099abea73eb",
            "bd4e1e6b4f1e46f1807a4b338ba2565a",
            "c125a61a7a1445488c78dffa8acb47cf",
            "e3d279e6c3c245ebae1397decb9281ad",
            "e75c59889e4f467595781640aa0b575a",
            "d3f543e1ec004e47adfaa8a170e0dbf5",
            "1d220747cf7a40459f14ec76c4ae6f07",
            "a792ff96ada64f3eae2a82b073657cbe",
            "d15d3e5175b74f60ad51350698c5199f",
            "2ca80599a6c1441998d01c3472d14da6",
            "5703ca92127d422bb002cc9f75509f93",
            "6a2c5f7d9f564ea194e47488d1156be2",
            "7df307db34c445e88a4206707ecd2a23",
            "5c2190a83d2f438787f4dae24c172d9c",
            "ff7e10ade6be4aa2973e21fea784a6a1",
            "56683fa9b3c0411abe351c00e58bd30b",
            "dc3dd07ca3954d61a773b57ec6f41fac",
            "fc30346c2fed43409abf9f2f7e87a2d0",
            "f4ed0b54a9064e8e80ad7e5d8c909f68",
            "8efd998eba084dc9965de646ee294113",
            "c6a206b64478449b8736a6fa6ca7db38",
            "5ea9cf668813400f86d519539dd020f3",
            "5da061ef0d2949e494193895ca009950",
            "df017358258740ada5f1cc6c834df122",
            "67370c9b64444c46877584825c6f982d",
            "8e03d6ac95ef401ab560e376fd3467a0",
            "d049e7763a74459a927ad5afd12e3709",
            "2d19ede889f64535a4263791187ef859",
            "2ba67b17fc4942dda20a3d5ee38aa9e6",
            "e203ac4ea3e34411a178f5f7f68203b4",
            "48a63987154e4a59b1f3f8d747044865",
            "3059654746274ed2abd9c34989037e9a",
            "f72d1114716e4ad1a592c7cbe62048d7",
            "c4ed1d90c26d44d3aa7bea466ef6d11c",
            "3001a417a3ec4531aff85da5be041b7d",
            "7b29305448714f86927b3a392c4d2cbf",
            "1f2b74ec06a541fdbb189bbedf5b01be",
            "d177d3b709414ca48e7df0d96efffdd7",
            "ba3dc6e38c5a4476a78849bc68ae32bb",
            "7f0375ecf2364c1c88eed4bb32f9f2fc",
            "002e1b7b24a541aabc852e564b675aa8",
            "61bc5257f6564ce4991110540306dcd3",
            "5bfeb895e0eb4a4aa73d4ecf429ab604",
            "c0039c70c8aa4c878899e75901999b77",
            "fc15a538ecd74af691253b5e01a8ab33",
            "f2c5af8a7391458d90028e597c7bc8f9",
            "8f16160c6eb4472fbcd51043e3800b35",
            "36a3bc785dfa497cbb15585bad5c5df9",
            "c4d15b4387a949678ad51ec0f314b329",
            "40cf5bd5dff5453db48821cebcb3b565",
            "f15cb44d21834898b5c5909343178d2f",
            "98e6f7ffd9db46aaa87e34e59f5786cf",
            "bd592bc8a8cb4656bd75cb6cdb035e49",
            "4a4346ec55344027b2d8bd8033ac5f2a",
            "3a3470f3c47f471299be17a566e4bebe",
            "a6a409510da242a1b7f135fd81e17f37",
            "4781905385464ee98d957e4210d3e1ce",
            "9ccd2e8e3ced4a67ae6803d6d9caac0e",
            "cf0411676f014c1cadea42e0d3bcc9cf",
            "29a34161d21f4890ac57133b47c7e684",
            "a9a620c2f4b54e80b4d5c7cb72abf976",
            "a8fffb769de846e29919882ad05e69c4",
            "e02cf20e55ab45389bde04db96c31b2a",
            "229a93cff19942fe89c01d3dc99d517c",
            "18a3a1901b4f4325978a9270bb47f233",
            "9e3d732e91a44db8a0d884a6d1f99139",
            "ed5d2aec689c49c59222ddbf4cfc2f83",
            "b322ad7df7b545b6a2666075421d3cb3",
            "be0605c3e045431aa489f159bbc29733",
            "78c68ba42b134b85979dde19e69c4468",
            "698d5a19f42f4dde85b99cfa7493152d",
            "72da34bb5795473aa1331e1621cb6a49",
            "92494b41d9ad440ba9213cee6c60b07a",
            "f21baa9638b94367bbfaa7b974901d6c",
            "868f9c715bcb40729014de10e4a7b2ec",
            "9a44f7b88b184707b88057edee1861ea",
            "ebeee8610da74e76824fd424f8ca267b",
            "389ae4f54a2a40558df017945f7ffb8b",
            "0f038ce3fd0d4dbcb04aa4ddb59b7fd9",
            "5ea241d2a111487abe7fe34f8731817d",
            "72623227cb1644da947f8848763b9098",
            "1266ea5009bd4c1e84ed3fe7f8592002",
            "870456e94e974d97ae39a18184d5695b",
            "cd99f77d366e40508f48da474995f27e",
            "98c06b7a8d47425baeb7ce8fe1199f82",
            "8457f53f4a7743a0aa4b8329302f252d",
            "b52af05e0bd146c0839a15e4729e165f",
            "987d759916294789a1dc7e888d0a9060",
            "82c9bf90d18a420a8d292f338f7956ff",
            "b39ab02ef733474692d4b04cf93abb08",
            "0e4a4e8d50434200b6cd18b7aa5820de",
            "89fce2fcbdd442f5bfc70c09044cc1ff",
            "70d03013efbe41df8a656f310406dc5a",
            "bbf2040223e846e3815d685ab37fed54",
            "073f3be169c14e70800cb4b87751bb66",
            "2e8691c91b1e4f079b93fcc29ff15d19",
            "81f1e3bc51374593920d69db26024fc3",
            "ce58a391eaea470ebb8123a9461179e8",
            "338a7e4f41bb4690b662dc3fd30d7ebe",
            "a223a0e5214e4bcb8ad92b72a2918500",
            "b9b7db3a2c3043adb01005db2a0bda57",
            "b7004ada81654ca69fb126d70b5de37a",
            "c17cafd4a69b43f18279553cb6c458d6",
            "f2b5e1bc173047f09f77dfc0fba8313c",
            "ac1eab1a90e14c11a3a710d07192f8c4",
            "105e32bb12f841999ffbfce4d8233104",
            "4a5f6effe59b470ea10aec5a5a47db7d",
            "4328f1fd44e04ed08d7229ba4cddffd0",
            "78dc35837b8548ca91c33b4c99a6dfb9",
            "0ca441fdd04744c4a30897c29912d057",
            "9d8b72763b604fcdab0e1a277292b4ea",
            "e21168d2665d42b7a25814e013d766f8",
            "2922199917e542c6abdadbfd6d4a42ac",
            "6a373b6468454960b2c12b14e5f1e2d7",
            "d7f5c54c365c41abb40fc9f08febbf37"
          ]
        },
        "id": "DtOqFv0W1hgv",
        "outputId": "835b83dc-b579-47a7-d4bb-5b57e8a26fdb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Found cached dataset parquet (/home/andreib/.cache/huggingface/datasets/ucberkeley-dlab___parquet/ucberkeley-dlab--measuring-hate-speech-c32713cabe528196/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
            "100%|██████████| 1/1 [00:00<00:00, 22.89it/s]\n",
            "Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/ucberkeley-dlab___parquet/ucberkeley-dlab--measuring-hate-speech-c32713cabe528196/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-f655188cf9fee53d.arrow\n",
            "Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/ucberkeley-dlab___parquet/ucberkeley-dlab--measuring-hate-speech-c32713cabe528196/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-3769ac5c3389ecd6.arrow\n",
            "Creating json from Arrow format: 100%|██████████| 22/22 [00:01<00:00, 14.43ba/s]\n",
            "Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/ucberkeley-dlab___parquet/ucberkeley-dlab--measuring-hate-speech-c32713cabe528196/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-ca13e93f24c3b31a.arrow\n",
            "Creating json from Arrow format: 100%|██████████| 16/16 [00:01<00:00, 14.37ba/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21585\n",
            "15578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 1\n",
        "\n",
        "import datasets\n",
        "from transformers import GPT2TokenizerFast\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import GPT2LMHeadModel\n",
        "import os\n",
        "from transformers import GPT2TokenizerFast, GPT2LMHeadModel, TrainingArguments, Trainer, default_data_collator\n",
        "import datasets\n",
        "import torch\n",
        "from itertools import chain\n",
        "\n",
        "if not os.path.isdir(\"trained_models\"):\n",
        "    os.mkdir(\"trained_models\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_id = \"gpt2\"\n",
        "\n",
        "dataset = datasets.load_dataset(\n",
        "    \"ucberkeley-dlab/measuring-hate-speech\",\n",
        "    \"binary\"\n",
        ")[\"train\"]\n",
        "\n",
        "dataset = dataset.filter(lambda example: example[\"target_race\"] == True)\n",
        "\n",
        "hate_speech_dataset = dataset.filter(lambda example: example[\"hate_speech_score\"] > 0.5)\n",
        "hate_speech_dataset.to_json(\"hate_speech_dataset.json\")\n",
        "\n",
        "supportive_speech_dataset = dataset.filter(lambda example: example[\"hate_speech_score\"] < -1)\n",
        "supportive_speech_dataset.to_json(\"supportive_speech_dataset.json\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wncsNklKUMyI",
        "outputId": "fa007e29-4ccb-4c33-9994-739706a13546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "05/01/2023 10:29:35 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/01/2023 10:29:35 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=train_models/runs/May01_10-29-35_andreib-Legion-5-Pro-16ACH6H,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=epoch,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=10.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=train_models,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=train_models,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=None,\n",
            "seed=41,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/01/2023 10:29:35 - INFO - datasets.builder - Using custom data configuration default-51675078709b1c06\n",
            "05/01/2023 10:29:35 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 10:29:35 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 10:29:35 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 10:29:35 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 10:29:35 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 223.54it/s]\n",
            "05/01/2023 10:29:36 - INFO - datasets.builder - Using custom data configuration default-51675078709b1c06\n",
            "05/01/2023 10:29:36 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 10:29:36 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 10:29:36 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 10:29:36 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 10:29:36 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 10:29:36 - INFO - datasets.builder - Using custom data configuration default-51675078709b1c06\n",
            "05/01/2023 10:29:36 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 10:29:36 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 10:29:36 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 10:29:36 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 10:29:36 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 10:29:36,586 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 10:29:36,587 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:502] 2023-05-01 10:29:36,717 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 10:29:36,851 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 10:29:36,852 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 10:29:37,119 >> loading file vocab.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 10:29:37,120 >> loading file merges.txt from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 10:29:37,120 >> loading file tokenizer.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 10:29:37,120 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 10:29:37,120 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 10:29:37,120 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 10:29:37,120 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 10:29:37,121 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:2534] 2023-05-01 10:29:37,180 >> loading weights file pytorch_model.bin from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/pytorch_model.bin\n",
            "[INFO|configuration_utils.py:575] 2023-05-01 10:29:37,327 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:3190] 2023-05-01 10:29:38,221 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:3198] 2023-05-01 10:29:38,221 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "[INFO|configuration_utils.py:537] 2023-05-01 10:29:38,342 >> loading configuration file generation_config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/generation_config.json\n",
            "[INFO|configuration_utils.py:575] 2023-05-01 10:29:38,342 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "05/01/2023 10:29:38 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-bacf955d4c268720.arrow\n",
            "05/01/2023 10:29:38 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-8add878477df40ee.arrow\n",
            "05/01/2023 10:29:38 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-62a22e0e8923528c.arrow\n",
            "05/01/2023 10:29:38 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-a3c247420d21f12a.arrow\n",
            "/home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1769] 2023-05-01 10:29:39,141 >> ***** Running training *****\n",
            "[INFO|trainer.py:1770] 2023-05-01 10:29:39,141 >>   Num examples = 738\n",
            "[INFO|trainer.py:1771] 2023-05-01 10:29:39,142 >>   Num Epochs = 10\n",
            "[INFO|trainer.py:1772] 2023-05-01 10:29:39,142 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1773] 2023-05-01 10:29:39,142 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1774] 2023-05-01 10:29:39,142 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1775] 2023-05-01 10:29:39,142 >>   Total optimization steps = 7,380\n",
            "[INFO|trainer.py:1776] 2023-05-01 10:29:39,142 >>   Number of trainable parameters = 124,439,808\n",
            "{'loss': 1.4157, 'learning_rate': 4.5e-05, 'epoch': 1.0}                        \n",
            " 10%|████                                    | 738/7380 [02:58<27:37,  4.01it/s][INFO|trainer.py:2868] 2023-05-01 10:32:37,741 >> Saving model checkpoint to train_models/checkpoint-738\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 10:32:37,742 >> Configuration saved in train_models/checkpoint-738/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 10:32:37,742 >> Configuration saved in train_models/checkpoint-738/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 10:32:38,169 >> Model weights saved in train_models/checkpoint-738/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 10:32:38,169 >> tokenizer config file saved in train_models/checkpoint-738/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 10:32:38,169 >> Special tokens file saved in train_models/checkpoint-738/special_tokens_map.json\n",
            "{'loss': 1.1488, 'learning_rate': 4e-05, 'epoch': 2.0}                          \n",
            " 20%|███████▊                               | 1476/7380 [06:02<24:15,  4.06it/s][INFO|trainer.py:2868] 2023-05-01 10:35:41,782 >> Saving model checkpoint to train_models/checkpoint-1476\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 10:35:41,782 >> Configuration saved in train_models/checkpoint-1476/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 10:35:41,783 >> Configuration saved in train_models/checkpoint-1476/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 10:35:42,209 >> Model weights saved in train_models/checkpoint-1476/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 10:35:42,209 >> tokenizer config file saved in train_models/checkpoint-1476/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 10:35:42,209 >> Special tokens file saved in train_models/checkpoint-1476/special_tokens_map.json\n",
            "{'loss': 1.0451, 'learning_rate': 3.5e-05, 'epoch': 3.0}                        \n",
            " 30%|███████████▋                           | 2214/7380 [09:06<21:32,  4.00it/s][INFO|trainer.py:2868] 2023-05-01 10:38:45,245 >> Saving model checkpoint to train_models/checkpoint-2214\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 10:38:45,246 >> Configuration saved in train_models/checkpoint-2214/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 10:38:45,246 >> Configuration saved in train_models/checkpoint-2214/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 10:38:45,699 >> Model weights saved in train_models/checkpoint-2214/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 10:38:45,699 >> tokenizer config file saved in train_models/checkpoint-2214/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 10:38:45,699 >> Special tokens file saved in train_models/checkpoint-2214/special_tokens_map.json\n",
            "{'loss': 0.9539, 'learning_rate': 3e-05, 'epoch': 4.0}                          \n",
            " 40%|███████████████▌                       | 2952/7380 [12:11<18:18,  4.03it/s][INFO|trainer.py:2868] 2023-05-01 10:41:50,941 >> Saving model checkpoint to train_models/checkpoint-2952\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 10:41:50,941 >> Configuration saved in train_models/checkpoint-2952/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 10:41:50,942 >> Configuration saved in train_models/checkpoint-2952/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 10:41:51,393 >> Model weights saved in train_models/checkpoint-2952/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 10:41:51,394 >> tokenizer config file saved in train_models/checkpoint-2952/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 10:41:51,394 >> Special tokens file saved in train_models/checkpoint-2952/special_tokens_map.json\n",
            "{'loss': 0.8746, 'learning_rate': 2.5e-05, 'epoch': 5.0}                        \n",
            " 50%|███████████████████▌                   | 3690/7380 [15:17<15:34,  3.95it/s][INFO|trainer.py:2868] 2023-05-01 10:44:56,329 >> Saving model checkpoint to train_models/checkpoint-3690\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 10:44:56,330 >> Configuration saved in train_models/checkpoint-3690/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 10:44:56,330 >> Configuration saved in train_models/checkpoint-3690/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 10:44:56,772 >> Model weights saved in train_models/checkpoint-3690/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 10:44:56,773 >> tokenizer config file saved in train_models/checkpoint-3690/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 10:44:56,773 >> Special tokens file saved in train_models/checkpoint-3690/special_tokens_map.json\n",
            "{'loss': 0.8065, 'learning_rate': 2e-05, 'epoch': 6.0}                          \n",
            " 60%|███████████████████████▍               | 4428/7380 [18:23<12:10,  4.04it/s][INFO|trainer.py:2868] 2023-05-01 10:48:02,854 >> Saving model checkpoint to train_models/checkpoint-4428\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 10:48:02,854 >> Configuration saved in train_models/checkpoint-4428/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 10:48:02,854 >> Configuration saved in train_models/checkpoint-4428/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 10:48:03,294 >> Model weights saved in train_models/checkpoint-4428/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 10:48:03,295 >> tokenizer config file saved in train_models/checkpoint-4428/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 10:48:03,295 >> Special tokens file saved in train_models/checkpoint-4428/special_tokens_map.json\n",
            "{'loss': 0.7507, 'learning_rate': 1.5e-05, 'epoch': 7.0}                        \n",
            " 70%|███████████████████████████▎           | 5166/7380 [21:28<09:08,  4.04it/s][INFO|trainer.py:2868] 2023-05-01 10:51:07,895 >> Saving model checkpoint to train_models/checkpoint-5166\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 10:51:07,895 >> Configuration saved in train_models/checkpoint-5166/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 10:51:07,895 >> Configuration saved in train_models/checkpoint-5166/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 10:51:08,335 >> Model weights saved in train_models/checkpoint-5166/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 10:51:08,336 >> tokenizer config file saved in train_models/checkpoint-5166/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 10:51:08,336 >> Special tokens file saved in train_models/checkpoint-5166/special_tokens_map.json\n",
            "{'loss': 0.7073, 'learning_rate': 1e-05, 'epoch': 8.0}                          \n",
            " 80%|███████████████████████████████▏       | 5904/7380 [24:35<06:12,  3.96it/s][INFO|trainer.py:2868] 2023-05-01 10:54:14,899 >> Saving model checkpoint to train_models/checkpoint-5904\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 10:54:14,900 >> Configuration saved in train_models/checkpoint-5904/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 10:54:14,900 >> Configuration saved in train_models/checkpoint-5904/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 10:54:15,353 >> Model weights saved in train_models/checkpoint-5904/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 10:54:15,353 >> tokenizer config file saved in train_models/checkpoint-5904/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 10:54:15,353 >> Special tokens file saved in train_models/checkpoint-5904/special_tokens_map.json\n",
            "{'loss': 0.6775, 'learning_rate': 5e-06, 'epoch': 9.0}                          \n",
            " 90%|███████████████████████████████████    | 6642/7380 [27:41<03:03,  4.02it/s][INFO|trainer.py:2868] 2023-05-01 10:57:20,858 >> Saving model checkpoint to train_models/checkpoint-6642\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 10:57:20,859 >> Configuration saved in train_models/checkpoint-6642/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 10:57:20,860 >> Configuration saved in train_models/checkpoint-6642/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 10:57:21,304 >> Model weights saved in train_models/checkpoint-6642/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 10:57:21,307 >> tokenizer config file saved in train_models/checkpoint-6642/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 10:57:21,308 >> Special tokens file saved in train_models/checkpoint-6642/special_tokens_map.json\n",
            "{'loss': 0.6577, 'learning_rate': 0.0, 'epoch': 10.0}                           \n",
            "100%|███████████████████████████████████████| 7380/7380 [30:47<00:00,  3.94it/s][INFO|trainer.py:2868] 2023-05-01 11:00:26,491 >> Saving model checkpoint to train_models/checkpoint-7380\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:00:26,491 >> Configuration saved in train_models/checkpoint-7380/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:00:26,492 >> Configuration saved in train_models/checkpoint-7380/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:00:26,940 >> Model weights saved in train_models/checkpoint-7380/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:00:26,940 >> tokenizer config file saved in train_models/checkpoint-7380/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:00:26,941 >> Special tokens file saved in train_models/checkpoint-7380/special_tokens_map.json\n",
            "[INFO|trainer.py:2039] 2023-05-01 11:00:27,897 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1848.7548, 'train_samples_per_second': 3.992, 'train_steps_per_second': 3.992, 'train_loss': 0.9037730767474911, 'epoch': 10.0}\n",
            "100%|███████████████████████████████████████| 7380/7380 [30:48<00:00,  3.99it/s]\n",
            "[INFO|trainer.py:2868] 2023-05-01 11:00:27,898 >> Saving model checkpoint to train_models\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:00:27,899 >> Configuration saved in train_models/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:00:27,899 >> Configuration saved in train_models/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:00:28,352 >> Model weights saved in train_models/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:00:28,352 >> tokenizer config file saved in train_models/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:00:28,352 >> Special tokens file saved in train_models/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  train_loss               =     0.9038\n",
            "  train_runtime            = 0:30:48.75\n",
            "  train_samples            =        738\n",
            "  train_samples_per_second =      3.992\n",
            "  train_steps_per_second   =      3.992\n",
            "[INFO|modelcard.py:451] 2023-05-01 11:00:28,732 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
            "05/01/2023 11:00:33 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/01/2023 11:00:33 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=train_models/runs/May01_11-00-33_andreib-Legion-5-Pro-16ACH6H,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=epoch,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=10.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=train_models,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=train_models,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/01/2023 11:00:33 - INFO - datasets.builder - Using custom data configuration default-51675078709b1c06\n",
            "05/01/2023 11:00:33 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 11:00:33 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 11:00:33 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 11:00:33 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 11:00:33 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 168.76it/s]\n",
            "05/01/2023 11:00:34 - INFO - datasets.builder - Using custom data configuration default-51675078709b1c06\n",
            "05/01/2023 11:00:34 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 11:00:34 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 11:00:34 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 11:00:34 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 11:00:34 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 11:00:34 - INFO - datasets.builder - Using custom data configuration default-51675078709b1c06\n",
            "05/01/2023 11:00:34 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 11:00:34 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 11:00:34 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 11:00:34 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 11:00:34 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 11:00:34,899 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 11:00:34,900 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:502] 2023-05-01 11:00:35,016 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 11:00:35,135 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 11:00:35,136 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 11:00:35,421 >> loading file vocab.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 11:00:35,421 >> loading file merges.txt from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 11:00:35,421 >> loading file tokenizer.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 11:00:35,421 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 11:00:35,421 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 11:00:35,421 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 11:00:35,421 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 11:00:35,421 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:2534] 2023-05-01 11:00:35,463 >> loading weights file pytorch_model.bin from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/pytorch_model.bin\n",
            "[INFO|configuration_utils.py:575] 2023-05-01 11:00:35,629 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:3190] 2023-05-01 11:00:36,588 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:3198] 2023-05-01 11:00:36,589 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "[INFO|configuration_utils.py:537] 2023-05-01 11:00:36,713 >> loading configuration file generation_config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/generation_config.json\n",
            "[INFO|configuration_utils.py:575] 2023-05-01 11:00:36,713 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "05/01/2023 11:00:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-bacf955d4c268720.arrow\n",
            "05/01/2023 11:00:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-8add878477df40ee.arrow\n",
            "05/01/2023 11:00:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-62a22e0e8923528c.arrow\n",
            "05/01/2023 11:00:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-a3c247420d21f12a.arrow\n",
            "/home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1769] 2023-05-01 11:00:37,513 >> ***** Running training *****\n",
            "[INFO|trainer.py:1770] 2023-05-01 11:00:37,513 >>   Num examples = 738\n",
            "[INFO|trainer.py:1771] 2023-05-01 11:00:37,513 >>   Num Epochs = 10\n",
            "[INFO|trainer.py:1772] 2023-05-01 11:00:37,513 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1773] 2023-05-01 11:00:37,513 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1774] 2023-05-01 11:00:37,513 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1775] 2023-05-01 11:00:37,513 >>   Total optimization steps = 7,380\n",
            "[INFO|trainer.py:1776] 2023-05-01 11:00:37,513 >>   Number of trainable parameters = 124,439,808\n",
            "{'loss': 1.4182, 'learning_rate': 4.5e-05, 'epoch': 1.0}                        \n",
            " 10%|████                                    | 738/7380 [03:05<27:59,  3.96it/s][INFO|trainer.py:2868] 2023-05-01 11:03:42,998 >> Saving model checkpoint to train_models/checkpoint-738\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:03:42,999 >> Configuration saved in train_models/checkpoint-738/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:03:42,999 >> Configuration saved in train_models/checkpoint-738/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:03:43,453 >> Model weights saved in train_models/checkpoint-738/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:03:43,454 >> tokenizer config file saved in train_models/checkpoint-738/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:03:43,454 >> Special tokens file saved in train_models/checkpoint-738/special_tokens_map.json\n",
            "{'loss': 1.1472, 'learning_rate': 4e-05, 'epoch': 2.0}                          \n",
            " 20%|███████▊                               | 1476/7380 [06:11<24:36,  4.00it/s][INFO|trainer.py:2868] 2023-05-01 11:06:48,730 >> Saving model checkpoint to train_models/checkpoint-1476\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:06:48,731 >> Configuration saved in train_models/checkpoint-1476/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:06:48,731 >> Configuration saved in train_models/checkpoint-1476/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:06:49,188 >> Model weights saved in train_models/checkpoint-1476/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:06:49,189 >> tokenizer config file saved in train_models/checkpoint-1476/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:06:49,189 >> Special tokens file saved in train_models/checkpoint-1476/special_tokens_map.json\n",
            "{'loss': 1.0417, 'learning_rate': 3.5e-05, 'epoch': 3.0}                        \n",
            " 30%|███████████▋                           | 2214/7380 [09:18<21:17,  4.04it/s][INFO|trainer.py:2868] 2023-05-01 11:09:55,874 >> Saving model checkpoint to train_models/checkpoint-2214\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:09:55,875 >> Configuration saved in train_models/checkpoint-2214/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:09:55,875 >> Configuration saved in train_models/checkpoint-2214/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:09:56,342 >> Model weights saved in train_models/checkpoint-2214/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:09:56,342 >> tokenizer config file saved in train_models/checkpoint-2214/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:09:56,342 >> Special tokens file saved in train_models/checkpoint-2214/special_tokens_map.json\n",
            "{'loss': 0.9503, 'learning_rate': 3e-05, 'epoch': 4.0}                          \n",
            " 40%|███████████████▌                       | 2952/7380 [12:24<18:29,  3.99it/s][INFO|trainer.py:2868] 2023-05-01 11:13:01,977 >> Saving model checkpoint to train_models/checkpoint-2952\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:13:01,978 >> Configuration saved in train_models/checkpoint-2952/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:13:01,978 >> Configuration saved in train_models/checkpoint-2952/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:13:02,451 >> Model weights saved in train_models/checkpoint-2952/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:13:02,451 >> tokenizer config file saved in train_models/checkpoint-2952/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:13:02,451 >> Special tokens file saved in train_models/checkpoint-2952/special_tokens_map.json\n",
            "{'loss': 0.8692, 'learning_rate': 2.5e-05, 'epoch': 5.0}                        \n",
            " 50%|███████████████████▌                   | 3690/7380 [15:31<15:25,  3.99it/s][INFO|trainer.py:2868] 2023-05-01 11:16:09,444 >> Saving model checkpoint to train_models/checkpoint-3690\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:16:09,445 >> Configuration saved in train_models/checkpoint-3690/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:16:09,445 >> Configuration saved in train_models/checkpoint-3690/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:16:09,885 >> Model weights saved in train_models/checkpoint-3690/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:16:09,886 >> tokenizer config file saved in train_models/checkpoint-3690/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:16:09,886 >> Special tokens file saved in train_models/checkpoint-3690/special_tokens_map.json\n",
            "{'loss': 0.802, 'learning_rate': 2e-05, 'epoch': 6.0}                           \n",
            " 60%|███████████████████████▍               | 4428/7380 [18:38<12:18,  4.00it/s][INFO|trainer.py:2868] 2023-05-01 11:19:15,564 >> Saving model checkpoint to train_models/checkpoint-4428\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:19:15,565 >> Configuration saved in train_models/checkpoint-4428/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:19:15,565 >> Configuration saved in train_models/checkpoint-4428/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:19:16,026 >> Model weights saved in train_models/checkpoint-4428/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:19:16,026 >> tokenizer config file saved in train_models/checkpoint-4428/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:19:16,026 >> Special tokens file saved in train_models/checkpoint-4428/special_tokens_map.json\n",
            "{'loss': 0.7463, 'learning_rate': 1.5e-05, 'epoch': 7.0}                        \n",
            " 70%|███████████████████████████▎           | 5166/7380 [21:45<09:21,  3.94it/s][INFO|trainer.py:2868] 2023-05-01 11:22:22,960 >> Saving model checkpoint to train_models/checkpoint-5166\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:22:22,960 >> Configuration saved in train_models/checkpoint-5166/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:22:22,960 >> Configuration saved in train_models/checkpoint-5166/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:22:23,430 >> Model weights saved in train_models/checkpoint-5166/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:22:23,430 >> tokenizer config file saved in train_models/checkpoint-5166/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:22:23,430 >> Special tokens file saved in train_models/checkpoint-5166/special_tokens_map.json\n",
            "{'loss': 0.7038, 'learning_rate': 1e-05, 'epoch': 8.0}                          \n",
            " 80%|███████████████████████████████▏       | 5904/7380 [24:50<06:07,  4.01it/s][INFO|trainer.py:2868] 2023-05-01 11:25:28,439 >> Saving model checkpoint to train_models/checkpoint-5904\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:25:28,440 >> Configuration saved in train_models/checkpoint-5904/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:25:28,440 >> Configuration saved in train_models/checkpoint-5904/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:25:28,880 >> Model weights saved in train_models/checkpoint-5904/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:25:28,881 >> tokenizer config file saved in train_models/checkpoint-5904/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:25:28,881 >> Special tokens file saved in train_models/checkpoint-5904/special_tokens_map.json\n",
            "{'loss': 0.6727, 'learning_rate': 5e-06, 'epoch': 9.0}                          \n",
            " 90%|███████████████████████████████████    | 6642/7380 [27:57<03:10,  3.88it/s][INFO|trainer.py:2868] 2023-05-01 11:28:35,005 >> Saving model checkpoint to train_models/checkpoint-6642\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:28:35,005 >> Configuration saved in train_models/checkpoint-6642/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:28:35,006 >> Configuration saved in train_models/checkpoint-6642/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:28:35,472 >> Model weights saved in train_models/checkpoint-6642/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:28:35,472 >> tokenizer config file saved in train_models/checkpoint-6642/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:28:35,472 >> Special tokens file saved in train_models/checkpoint-6642/special_tokens_map.json\n",
            "{'loss': 0.6535, 'learning_rate': 0.0, 'epoch': 10.0}                           \n",
            "100%|███████████████████████████████████████| 7380/7380 [31:04<00:00,  3.99it/s][INFO|trainer.py:2868] 2023-05-01 11:31:41,839 >> Saving model checkpoint to train_models/checkpoint-7380\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:31:41,840 >> Configuration saved in train_models/checkpoint-7380/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:31:41,840 >> Configuration saved in train_models/checkpoint-7380/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:31:42,285 >> Model weights saved in train_models/checkpoint-7380/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:31:42,285 >> tokenizer config file saved in train_models/checkpoint-7380/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:31:42,286 >> Special tokens file saved in train_models/checkpoint-7380/special_tokens_map.json\n",
            "[INFO|trainer.py:2039] 2023-05-01 11:31:43,233 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1865.7205, 'train_samples_per_second': 3.956, 'train_steps_per_second': 3.956, 'train_loss': 0.9004806022333905, 'epoch': 10.0}\n",
            "100%|███████████████████████████████████████| 7380/7380 [31:05<00:00,  3.96it/s]\n",
            "[INFO|trainer.py:2868] 2023-05-01 11:31:43,235 >> Saving model checkpoint to train_models\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:31:43,235 >> Configuration saved in train_models/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:31:43,236 >> Configuration saved in train_models/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:31:43,721 >> Model weights saved in train_models/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:31:43,721 >> tokenizer config file saved in train_models/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:31:43,721 >> Special tokens file saved in train_models/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  train_loss               =     0.9005\n",
            "  train_runtime            = 0:31:05.72\n",
            "  train_samples            =        738\n",
            "  train_samples_per_second =      3.956\n",
            "  train_steps_per_second   =      3.956\n",
            "[INFO|modelcard.py:451] 2023-05-01 11:31:44,124 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
            "05/01/2023 11:31:47 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/01/2023 11:31:47 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=train_models/runs/May01_11-31-46_andreib-Legion-5-Pro-16ACH6H,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=epoch,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=10.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=train_models,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=train_models,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=None,\n",
            "seed=43,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/01/2023 11:31:47 - INFO - datasets.builder - Using custom data configuration default-51675078709b1c06\n",
            "05/01/2023 11:31:47 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 11:31:47 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 11:31:47 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 11:31:47 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 11:31:47 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 166.69it/s]\n",
            "05/01/2023 11:31:47 - INFO - datasets.builder - Using custom data configuration default-51675078709b1c06\n",
            "05/01/2023 11:31:47 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 11:31:47 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 11:31:47 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 11:31:47 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 11:31:47 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 11:31:48 - INFO - datasets.builder - Using custom data configuration default-51675078709b1c06\n",
            "05/01/2023 11:31:48 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 11:31:48 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 11:31:48 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 11:31:48 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 11:31:48 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 11:31:48,521 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 11:31:48,522 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:502] 2023-05-01 11:31:48,645 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 11:31:48,761 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 11:31:48,762 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 11:31:49,022 >> loading file vocab.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 11:31:49,022 >> loading file merges.txt from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 11:31:49,022 >> loading file tokenizer.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 11:31:49,022 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 11:31:49,022 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 11:31:49,022 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 11:31:49,022 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 11:31:49,023 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:2534] 2023-05-01 11:31:49,077 >> loading weights file pytorch_model.bin from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/pytorch_model.bin\n",
            "[INFO|configuration_utils.py:575] 2023-05-01 11:31:49,267 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:3190] 2023-05-01 11:31:50,248 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:3198] 2023-05-01 11:31:50,248 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "[INFO|configuration_utils.py:537] 2023-05-01 11:31:50,368 >> loading configuration file generation_config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/generation_config.json\n",
            "[INFO|configuration_utils.py:575] 2023-05-01 11:31:50,369 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "05/01/2023 11:31:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-bacf955d4c268720.arrow\n",
            "05/01/2023 11:31:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-8add878477df40ee.arrow\n",
            "05/01/2023 11:31:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-62a22e0e8923528c.arrow\n",
            "05/01/2023 11:31:50 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-51675078709b1c06/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-a3c247420d21f12a.arrow\n",
            "/home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1769] 2023-05-01 11:31:51,200 >> ***** Running training *****\n",
            "[INFO|trainer.py:1770] 2023-05-01 11:31:51,200 >>   Num examples = 738\n",
            "[INFO|trainer.py:1771] 2023-05-01 11:31:51,200 >>   Num Epochs = 10\n",
            "[INFO|trainer.py:1772] 2023-05-01 11:31:51,200 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1773] 2023-05-01 11:31:51,200 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1774] 2023-05-01 11:31:51,200 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1775] 2023-05-01 11:31:51,200 >>   Total optimization steps = 7,380\n",
            "[INFO|trainer.py:1776] 2023-05-01 11:31:51,200 >>   Number of trainable parameters = 124,439,808\n",
            "{'loss': 1.4149, 'learning_rate': 4.5e-05, 'epoch': 1.0}                        \n",
            " 10%|████                                    | 738/7380 [03:06<27:15,  4.06it/s][INFO|trainer.py:2868] 2023-05-01 11:34:57,561 >> Saving model checkpoint to train_models/checkpoint-738\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:34:57,562 >> Configuration saved in train_models/checkpoint-738/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:34:57,562 >> Configuration saved in train_models/checkpoint-738/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:34:58,012 >> Model weights saved in train_models/checkpoint-738/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:34:58,013 >> tokenizer config file saved in train_models/checkpoint-738/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:34:58,013 >> Special tokens file saved in train_models/checkpoint-738/special_tokens_map.json\n",
            "{'loss': 1.1469, 'learning_rate': 4e-05, 'epoch': 2.0}                          \n",
            " 20%|███████▊                               | 1476/7380 [06:09<24:35,  4.00it/s][INFO|trainer.py:2868] 2023-05-01 11:38:00,975 >> Saving model checkpoint to train_models/checkpoint-1476\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:38:00,976 >> Configuration saved in train_models/checkpoint-1476/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:38:00,976 >> Configuration saved in train_models/checkpoint-1476/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:38:01,435 >> Model weights saved in train_models/checkpoint-1476/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:38:01,436 >> tokenizer config file saved in train_models/checkpoint-1476/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:38:01,436 >> Special tokens file saved in train_models/checkpoint-1476/special_tokens_map.json\n",
            "{'loss': 1.0436, 'learning_rate': 3.5e-05, 'epoch': 3.0}                        \n",
            " 30%|███████████▋                           | 2214/7380 [09:26<23:37,  3.64it/s][INFO|trainer.py:2868] 2023-05-01 11:41:17,932 >> Saving model checkpoint to train_models/checkpoint-2214\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:41:17,933 >> Configuration saved in train_models/checkpoint-2214/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:41:17,933 >> Configuration saved in train_models/checkpoint-2214/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:41:18,409 >> Model weights saved in train_models/checkpoint-2214/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:41:18,409 >> tokenizer config file saved in train_models/checkpoint-2214/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:41:18,410 >> Special tokens file saved in train_models/checkpoint-2214/special_tokens_map.json\n",
            "{'loss': 0.9522, 'learning_rate': 3e-05, 'epoch': 4.0}                          \n",
            " 40%|███████████████▌                       | 2952/7380 [12:46<20:52,  3.54it/s][INFO|trainer.py:2868] 2023-05-01 11:44:37,979 >> Saving model checkpoint to train_models/checkpoint-2952\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:44:37,979 >> Configuration saved in train_models/checkpoint-2952/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:44:37,980 >> Configuration saved in train_models/checkpoint-2952/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:44:38,463 >> Model weights saved in train_models/checkpoint-2952/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:44:38,463 >> tokenizer config file saved in train_models/checkpoint-2952/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:44:38,464 >> Special tokens file saved in train_models/checkpoint-2952/special_tokens_map.json\n",
            "{'loss': 0.8721, 'learning_rate': 2.5e-05, 'epoch': 5.0}                        \n",
            " 50%|███████████████████▌                   | 3690/7380 [16:09<16:57,  3.63it/s][INFO|trainer.py:2868] 2023-05-01 11:48:01,049 >> Saving model checkpoint to train_models/checkpoint-3690\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:48:01,049 >> Configuration saved in train_models/checkpoint-3690/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:48:01,049 >> Configuration saved in train_models/checkpoint-3690/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:48:01,535 >> Model weights saved in train_models/checkpoint-3690/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:48:01,536 >> tokenizer config file saved in train_models/checkpoint-3690/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:48:01,536 >> Special tokens file saved in train_models/checkpoint-3690/special_tokens_map.json\n",
            "{'loss': 0.8044, 'learning_rate': 2e-05, 'epoch': 6.0}                          \n",
            " 60%|███████████████████████▍               | 4428/7380 [19:30<14:22,  3.42it/s][INFO|trainer.py:2868] 2023-05-01 11:51:22,046 >> Saving model checkpoint to train_models/checkpoint-4428\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:51:22,047 >> Configuration saved in train_models/checkpoint-4428/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:51:22,047 >> Configuration saved in train_models/checkpoint-4428/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:51:22,558 >> Model weights saved in train_models/checkpoint-4428/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:51:22,558 >> tokenizer config file saved in train_models/checkpoint-4428/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:51:22,558 >> Special tokens file saved in train_models/checkpoint-4428/special_tokens_map.json\n",
            "{'loss': 0.7497, 'learning_rate': 1.5e-05, 'epoch': 7.0}                        \n",
            " 70%|███████████████████████████▎           | 5166/7380 [22:52<10:58,  3.36it/s][INFO|trainer.py:2868] 2023-05-01 11:54:43,551 >> Saving model checkpoint to train_models/checkpoint-5166\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:54:43,551 >> Configuration saved in train_models/checkpoint-5166/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:54:43,551 >> Configuration saved in train_models/checkpoint-5166/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:54:44,086 >> Model weights saved in train_models/checkpoint-5166/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:54:44,087 >> tokenizer config file saved in train_models/checkpoint-5166/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:54:44,087 >> Special tokens file saved in train_models/checkpoint-5166/special_tokens_map.json\n",
            "{'loss': 0.7065, 'learning_rate': 1e-05, 'epoch': 8.0}                          \n",
            " 80%|███████████████████████████████▏       | 5904/7380 [26:16<06:06,  4.02it/s][INFO|trainer.py:2868] 2023-05-01 11:58:07,895 >> Saving model checkpoint to train_models/checkpoint-5904\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 11:58:07,896 >> Configuration saved in train_models/checkpoint-5904/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 11:58:07,897 >> Configuration saved in train_models/checkpoint-5904/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 11:58:08,357 >> Model weights saved in train_models/checkpoint-5904/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 11:58:08,358 >> tokenizer config file saved in train_models/checkpoint-5904/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 11:58:08,358 >> Special tokens file saved in train_models/checkpoint-5904/special_tokens_map.json\n",
            "{'loss': 0.6757, 'learning_rate': 5e-06, 'epoch': 9.0}                          \n",
            " 90%|███████████████████████████████████    | 6642/7380 [29:23<03:07,  3.93it/s][INFO|trainer.py:2868] 2023-05-01 12:01:14,936 >> Saving model checkpoint to train_models/checkpoint-6642\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:01:14,937 >> Configuration saved in train_models/checkpoint-6642/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:01:14,937 >> Configuration saved in train_models/checkpoint-6642/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:01:15,390 >> Model weights saved in train_models/checkpoint-6642/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:01:15,391 >> tokenizer config file saved in train_models/checkpoint-6642/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:01:15,391 >> Special tokens file saved in train_models/checkpoint-6642/special_tokens_map.json\n",
            "{'loss': 0.6568, 'learning_rate': 0.0, 'epoch': 10.0}                           \n",
            "100%|███████████████████████████████████████| 7380/7380 [32:44<00:00,  3.62it/s][INFO|trainer.py:2868] 2023-05-01 12:04:35,685 >> Saving model checkpoint to train_models/checkpoint-7380\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:04:35,685 >> Configuration saved in train_models/checkpoint-7380/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:04:35,686 >> Configuration saved in train_models/checkpoint-7380/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:04:36,190 >> Model weights saved in train_models/checkpoint-7380/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:04:36,190 >> tokenizer config file saved in train_models/checkpoint-7380/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:04:36,190 >> Special tokens file saved in train_models/checkpoint-7380/special_tokens_map.json\n",
            "[INFO|trainer.py:2039] 2023-05-01 12:04:37,267 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1966.0672, 'train_samples_per_second': 3.754, 'train_steps_per_second': 3.754, 'train_loss': 0.9022713472526571, 'epoch': 10.0}\n",
            "100%|███████████████████████████████████████| 7380/7380 [32:46<00:00,  3.75it/s]\n",
            "[INFO|trainer.py:2868] 2023-05-01 12:04:37,269 >> Saving model checkpoint to train_models\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:04:37,270 >> Configuration saved in train_models/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:04:37,270 >> Configuration saved in train_models/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:04:37,783 >> Model weights saved in train_models/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:04:37,784 >> tokenizer config file saved in train_models/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:04:37,784 >> Special tokens file saved in train_models/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  train_loss               =     0.9023\n",
            "  train_runtime            = 0:32:46.06\n",
            "  train_samples            =        738\n",
            "  train_samples_per_second =      3.754\n",
            "  train_steps_per_second   =      3.754\n",
            "[INFO|modelcard.py:451] 2023-05-01 12:04:38,160 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
          ]
        }
      ],
      "source": [
        "!bash train_models.sh hate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_Z0usT7xtkZ",
        "outputId": "9427bdb0-f9b1-4d11-a576-7c1cdf8e9cc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "05/01/2023 12:06:29 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/01/2023 12:06:29 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=train_models/runs/May01_12-06-29_andreib-Legion-5-Pro-16ACH6H,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=epoch,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=10.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=train_models,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=train_models,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=None,\n",
            "seed=41,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/01/2023 12:06:30 - INFO - datasets.builder - Using custom data configuration default-3e166d1c2d527ed4\n",
            "05/01/2023 12:06:30 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 12:06:30 - INFO - datasets.builder - Generating dataset json (/home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "Downloading and preparing dataset json/default to /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n",
            "Downloading data files: 100%|███████████████████| 1/1 [00:00<00:00, 8289.14it/s]\n",
            "05/01/2023 12:06:30 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
            "05/01/2023 12:06:30 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
            "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1094.26it/s]\n",
            "05/01/2023 12:06:30 - INFO - datasets.builder - Generating train split\n",
            "05/01/2023 12:06:30 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset json downloaded and prepared to /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 255.84it/s]\n",
            "05/01/2023 12:06:30 - INFO - datasets.builder - Using custom data configuration default-3e166d1c2d527ed4\n",
            "05/01/2023 12:06:30 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 12:06:30 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 12:06:30 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 12:06:30 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 12:06:30 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 12:06:31 - INFO - datasets.builder - Using custom data configuration default-3e166d1c2d527ed4\n",
            "05/01/2023 12:06:31 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 12:06:31 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 12:06:31 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 12:06:31 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 12:06:31 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 12:06:31,418 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 12:06:31,419 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:502] 2023-05-01 12:06:31,535 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 12:06:31,654 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 12:06:31,655 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:06:31,901 >> loading file vocab.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:06:31,901 >> loading file merges.txt from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:06:31,901 >> loading file tokenizer.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:06:31,901 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:06:31,901 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:06:31,901 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 12:06:31,902 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 12:06:31,902 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:2534] 2023-05-01 12:06:31,956 >> loading weights file pytorch_model.bin from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/pytorch_model.bin\n",
            "[INFO|configuration_utils.py:575] 2023-05-01 12:06:32,175 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:3190] 2023-05-01 12:06:33,203 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:3198] 2023-05-01 12:06:33,203 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "[INFO|configuration_utils.py:537] 2023-05-01 12:06:33,322 >> loading configuration file generation_config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/generation_config.json\n",
            "[INFO|configuration_utils.py:575] 2023-05-01 12:06:33,322 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "Running tokenizer on dataset:   0%|            | 0/14799 [00:00<?, ? examples/s]05/01/2023 12:06:33 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-cf508a405cade77c.arrow\n",
            "Running tokenizer on dataset:   0%|              | 0/779 [00:00<?, ? examples/s]05/01/2023 12:06:33 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-214f26defabb7fc1.arrow\n",
            "Grouping texts in chunks of 1024:   0%|        | 0/14799 [00:00<?, ? examples/s]05/01/2023 12:06:33 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-e4b2e9b2d959e943.arrow\n",
            "Grouping texts in chunks of 1024:   0%|          | 0/779 [00:00<?, ? examples/s]05/01/2023 12:06:34 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-7855d5e3d79f83cc.arrow\n",
            "/home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1769] 2023-05-01 12:06:35,085 >> ***** Running training *****\n",
            "[INFO|trainer.py:1770] 2023-05-01 12:06:35,085 >>   Num examples = 549\n",
            "[INFO|trainer.py:1771] 2023-05-01 12:06:35,085 >>   Num Epochs = 10\n",
            "[INFO|trainer.py:1772] 2023-05-01 12:06:35,085 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1773] 2023-05-01 12:06:35,085 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1774] 2023-05-01 12:06:35,085 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1775] 2023-05-01 12:06:35,085 >>   Total optimization steps = 5,490\n",
            "[INFO|trainer.py:1776] 2023-05-01 12:06:35,085 >>   Number of trainable parameters = 124,439,808\n",
            "{'loss': 3.2521, 'learning_rate': 4.5e-05, 'epoch': 1.0}                        \n",
            " 10%|████                                    | 549/5490 [02:18<20:10,  4.08it/s][INFO|trainer.py:2868] 2023-05-01 12:08:53,152 >> Saving model checkpoint to train_models/checkpoint-549\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:08:53,153 >> Configuration saved in train_models/checkpoint-549/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:08:53,153 >> Configuration saved in train_models/checkpoint-549/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:08:53,608 >> Model weights saved in train_models/checkpoint-549/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:08:53,608 >> tokenizer config file saved in train_models/checkpoint-549/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:08:53,608 >> Special tokens file saved in train_models/checkpoint-549/special_tokens_map.json\n",
            "{'loss': 2.8836, 'learning_rate': 4e-05, 'epoch': 2.0}                          \n",
            " 20%|███████▊                               | 1098/5490 [04:36<16:45,  4.37it/s][INFO|trainer.py:2868] 2023-05-01 12:11:11,537 >> Saving model checkpoint to train_models/checkpoint-1098\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:11:11,537 >> Configuration saved in train_models/checkpoint-1098/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:11:11,537 >> Configuration saved in train_models/checkpoint-1098/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:11:12,002 >> Model weights saved in train_models/checkpoint-1098/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:11:12,003 >> tokenizer config file saved in train_models/checkpoint-1098/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:11:12,004 >> Special tokens file saved in train_models/checkpoint-1098/special_tokens_map.json\n",
            "{'loss': 2.6469, 'learning_rate': 3.5e-05, 'epoch': 3.0}                        \n",
            " 30%|███████████▋                           | 1647/5490 [06:55<16:20,  3.92it/s][INFO|trainer.py:2868] 2023-05-01 12:13:30,568 >> Saving model checkpoint to train_models/checkpoint-1647\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:13:30,569 >> Configuration saved in train_models/checkpoint-1647/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:13:30,569 >> Configuration saved in train_models/checkpoint-1647/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:13:31,041 >> Model weights saved in train_models/checkpoint-1647/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:13:31,041 >> tokenizer config file saved in train_models/checkpoint-1647/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:13:31,041 >> Special tokens file saved in train_models/checkpoint-1647/special_tokens_map.json\n",
            "{'loss': 2.4481, 'learning_rate': 3e-05, 'epoch': 4.0}                          \n",
            " 40%|███████████████▌                       | 2196/5490 [09:19<14:21,  3.83it/s][INFO|trainer.py:2868] 2023-05-01 12:15:54,785 >> Saving model checkpoint to train_models/checkpoint-2196\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:15:54,785 >> Configuration saved in train_models/checkpoint-2196/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:15:54,786 >> Configuration saved in train_models/checkpoint-2196/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:15:55,360 >> Model weights saved in train_models/checkpoint-2196/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:15:55,360 >> tokenizer config file saved in train_models/checkpoint-2196/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:15:55,360 >> Special tokens file saved in train_models/checkpoint-2196/special_tokens_map.json\n",
            "{'loss': 2.2806, 'learning_rate': 2.5e-05, 'epoch': 5.0}                        \n",
            " 50%|███████████████████▌                   | 2745/5490 [11:41<11:24,  4.01it/s][INFO|trainer.py:2868] 2023-05-01 12:18:16,491 >> Saving model checkpoint to train_models/checkpoint-2745\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:18:16,492 >> Configuration saved in train_models/checkpoint-2745/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:18:16,492 >> Configuration saved in train_models/checkpoint-2745/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:18:16,949 >> Model weights saved in train_models/checkpoint-2745/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:18:16,949 >> tokenizer config file saved in train_models/checkpoint-2745/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:18:16,949 >> Special tokens file saved in train_models/checkpoint-2745/special_tokens_map.json\n",
            "{'loss': 2.1438, 'learning_rate': 2e-05, 'epoch': 6.0}                          \n",
            " 60%|███████████████████████▍               | 3294/5490 [14:02<09:10,  3.99it/s][INFO|trainer.py:2868] 2023-05-01 12:20:37,728 >> Saving model checkpoint to train_models/checkpoint-3294\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:20:37,728 >> Configuration saved in train_models/checkpoint-3294/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:20:37,729 >> Configuration saved in train_models/checkpoint-3294/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:20:38,187 >> Model weights saved in train_models/checkpoint-3294/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:20:38,188 >> tokenizer config file saved in train_models/checkpoint-3294/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:20:38,188 >> Special tokens file saved in train_models/checkpoint-3294/special_tokens_map.json\n",
            "{'loss': 2.0345, 'learning_rate': 1.5e-05, 'epoch': 7.0}                        \n",
            " 70%|███████████████████████████▎           | 3843/5490 [16:26<06:58,  3.94it/s][INFO|trainer.py:2868] 2023-05-01 12:23:01,460 >> Saving model checkpoint to train_models/checkpoint-3843\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:23:01,461 >> Configuration saved in train_models/checkpoint-3843/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:23:01,461 >> Configuration saved in train_models/checkpoint-3843/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:23:01,902 >> Model weights saved in train_models/checkpoint-3843/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:23:01,902 >> tokenizer config file saved in train_models/checkpoint-3843/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:23:01,902 >> Special tokens file saved in train_models/checkpoint-3843/special_tokens_map.json\n",
            "{'loss': 1.948, 'learning_rate': 1e-05, 'epoch': 8.0}                           \n",
            " 80%|███████████████████████████████▏       | 4392/5490 [18:48<04:31,  4.05it/s][INFO|trainer.py:2868] 2023-05-01 12:25:23,752 >> Saving model checkpoint to train_models/checkpoint-4392\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:25:23,753 >> Configuration saved in train_models/checkpoint-4392/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:25:23,753 >> Configuration saved in train_models/checkpoint-4392/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:25:24,217 >> Model weights saved in train_models/checkpoint-4392/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:25:24,218 >> tokenizer config file saved in train_models/checkpoint-4392/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:25:24,218 >> Special tokens file saved in train_models/checkpoint-4392/special_tokens_map.json\n",
            "{'loss': 1.8908, 'learning_rate': 5e-06, 'epoch': 9.0}                          \n",
            " 90%|███████████████████████████████████    | 4941/5490 [21:06<02:14,  4.09it/s][INFO|trainer.py:2868] 2023-05-01 12:27:41,787 >> Saving model checkpoint to train_models/checkpoint-4941\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:27:41,788 >> Configuration saved in train_models/checkpoint-4941/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:27:41,788 >> Configuration saved in train_models/checkpoint-4941/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:27:42,248 >> Model weights saved in train_models/checkpoint-4941/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:27:42,249 >> tokenizer config file saved in train_models/checkpoint-4941/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:27:42,249 >> Special tokens file saved in train_models/checkpoint-4941/special_tokens_map.json\n",
            "{'loss': 1.8541, 'learning_rate': 0.0, 'epoch': 10.0}                           \n",
            "100%|███████████████████████████████████████| 5490/5490 [23:30<00:00,  3.60it/s][INFO|trainer.py:2868] 2023-05-01 12:30:05,237 >> Saving model checkpoint to train_models/checkpoint-5490\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:30:05,238 >> Configuration saved in train_models/checkpoint-5490/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:30:05,238 >> Configuration saved in train_models/checkpoint-5490/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:30:05,735 >> Model weights saved in train_models/checkpoint-5490/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:30:05,735 >> tokenizer config file saved in train_models/checkpoint-5490/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:30:05,735 >> Special tokens file saved in train_models/checkpoint-5490/special_tokens_map.json\n",
            "[INFO|trainer.py:2039] 2023-05-01 12:30:06,791 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1411.7061, 'train_samples_per_second': 3.889, 'train_steps_per_second': 3.889, 'train_loss': 2.3382404487206854, 'epoch': 10.0}\n",
            "100%|███████████████████████████████████████| 5490/5490 [23:31<00:00,  3.89it/s]\n",
            "[INFO|trainer.py:2868] 2023-05-01 12:30:06,793 >> Saving model checkpoint to train_models\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:30:06,794 >> Configuration saved in train_models/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:30:06,794 >> Configuration saved in train_models/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:30:07,334 >> Model weights saved in train_models/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:30:07,336 >> tokenizer config file saved in train_models/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:30:07,336 >> Special tokens file saved in train_models/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  train_loss               =     2.3382\n",
            "  train_runtime            = 0:23:31.70\n",
            "  train_samples            =        549\n",
            "  train_samples_per_second =      3.889\n",
            "  train_steps_per_second   =      3.889\n",
            "[INFO|modelcard.py:451] 2023-05-01 12:30:07,745 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
            "05/01/2023 12:30:10 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/01/2023 12:30:10 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=train_models/runs/May01_12-30-10_andreib-Legion-5-Pro-16ACH6H,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=epoch,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=10.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=train_models,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=train_models,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/01/2023 12:30:11 - INFO - datasets.builder - Using custom data configuration default-3e166d1c2d527ed4\n",
            "05/01/2023 12:30:11 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 12:30:11 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 12:30:11 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 12:30:11 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 12:30:11 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 176.34it/s]\n",
            "05/01/2023 12:30:11 - INFO - datasets.builder - Using custom data configuration default-3e166d1c2d527ed4\n",
            "05/01/2023 12:30:11 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 12:30:11 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 12:30:11 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 12:30:11 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 12:30:11 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 12:30:12 - INFO - datasets.builder - Using custom data configuration default-3e166d1c2d527ed4\n",
            "05/01/2023 12:30:12 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 12:30:12 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 12:30:12 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 12:30:12 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 12:30:12 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 12:30:12,243 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 12:30:12,243 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:502] 2023-05-01 12:30:12,361 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 12:30:12,482 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 12:30:12,482 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:30:12,734 >> loading file vocab.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:30:12,734 >> loading file merges.txt from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:30:12,734 >> loading file tokenizer.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:30:12,734 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:30:12,734 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:30:12,734 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 12:30:12,734 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 12:30:12,735 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:2534] 2023-05-01 12:30:12,788 >> loading weights file pytorch_model.bin from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/pytorch_model.bin\n",
            "[INFO|configuration_utils.py:575] 2023-05-01 12:30:13,023 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:3190] 2023-05-01 12:30:14,021 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:3198] 2023-05-01 12:30:14,021 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "[INFO|configuration_utils.py:537] 2023-05-01 12:30:14,140 >> loading configuration file generation_config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/generation_config.json\n",
            "[INFO|configuration_utils.py:575] 2023-05-01 12:30:14,140 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "05/01/2023 12:30:14 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-cf508a405cade77c.arrow\n",
            "05/01/2023 12:30:14 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-214f26defabb7fc1.arrow\n",
            "05/01/2023 12:30:14 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-e4b2e9b2d959e943.arrow\n",
            "05/01/2023 12:30:14 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-7855d5e3d79f83cc.arrow\n",
            "/home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1769] 2023-05-01 12:30:15,163 >> ***** Running training *****\n",
            "[INFO|trainer.py:1770] 2023-05-01 12:30:15,163 >>   Num examples = 549\n",
            "[INFO|trainer.py:1771] 2023-05-01 12:30:15,163 >>   Num Epochs = 10\n",
            "[INFO|trainer.py:1772] 2023-05-01 12:30:15,163 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1773] 2023-05-01 12:30:15,163 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1774] 2023-05-01 12:30:15,163 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1775] 2023-05-01 12:30:15,163 >>   Total optimization steps = 5,490\n",
            "[INFO|trainer.py:1776] 2023-05-01 12:30:15,164 >>   Number of trainable parameters = 124,439,808\n",
            "{'loss': 3.2514, 'learning_rate': 4.5e-05, 'epoch': 1.0}                        \n",
            " 10%|████                                    | 549/5490 [02:22<20:31,  4.01it/s][INFO|trainer.py:2868] 2023-05-01 12:32:37,724 >> Saving model checkpoint to train_models/checkpoint-549\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:32:37,725 >> Configuration saved in train_models/checkpoint-549/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:32:37,725 >> Configuration saved in train_models/checkpoint-549/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:32:38,211 >> Model weights saved in train_models/checkpoint-549/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:32:38,211 >> tokenizer config file saved in train_models/checkpoint-549/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:32:38,211 >> Special tokens file saved in train_models/checkpoint-549/special_tokens_map.json\n",
            "{'loss': 2.8805, 'learning_rate': 4e-05, 'epoch': 2.0}                          \n",
            " 20%|███████▊                               | 1098/5490 [04:42<18:10,  4.03it/s][INFO|trainer.py:2868] 2023-05-01 12:34:57,489 >> Saving model checkpoint to train_models/checkpoint-1098\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:34:57,489 >> Configuration saved in train_models/checkpoint-1098/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:34:57,490 >> Configuration saved in train_models/checkpoint-1098/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:34:57,947 >> Model weights saved in train_models/checkpoint-1098/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:34:57,948 >> tokenizer config file saved in train_models/checkpoint-1098/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:34:57,948 >> Special tokens file saved in train_models/checkpoint-1098/special_tokens_map.json\n",
            "{'loss': 2.6443, 'learning_rate': 3.5e-05, 'epoch': 3.0}                        \n",
            " 30%|███████████▋                           | 1647/5490 [07:02<15:45,  4.06it/s][INFO|trainer.py:2868] 2023-05-01 12:37:18,131 >> Saving model checkpoint to train_models/checkpoint-1647\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:37:18,131 >> Configuration saved in train_models/checkpoint-1647/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:37:18,131 >> Configuration saved in train_models/checkpoint-1647/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:37:18,594 >> Model weights saved in train_models/checkpoint-1647/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:37:18,594 >> tokenizer config file saved in train_models/checkpoint-1647/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:37:18,594 >> Special tokens file saved in train_models/checkpoint-1647/special_tokens_map.json\n",
            "{'loss': 2.4474, 'learning_rate': 3e-05, 'epoch': 4.0}                          \n",
            " 40%|███████████████▌                       | 2196/5490 [09:22<13:32,  4.05it/s][INFO|trainer.py:2868] 2023-05-01 12:39:38,053 >> Saving model checkpoint to train_models/checkpoint-2196\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:39:38,054 >> Configuration saved in train_models/checkpoint-2196/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:39:38,054 >> Configuration saved in train_models/checkpoint-2196/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:39:38,512 >> Model weights saved in train_models/checkpoint-2196/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:39:38,513 >> tokenizer config file saved in train_models/checkpoint-2196/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:39:38,513 >> Special tokens file saved in train_models/checkpoint-2196/special_tokens_map.json\n",
            "{'loss': 2.2803, 'learning_rate': 2.5e-05, 'epoch': 5.0}                        \n",
            " 50%|███████████████████▌                   | 2745/5490 [11:42<11:16,  4.06it/s][INFO|trainer.py:2868] 2023-05-01 12:41:58,066 >> Saving model checkpoint to train_models/checkpoint-2745\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:41:58,066 >> Configuration saved in train_models/checkpoint-2745/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:41:58,067 >> Configuration saved in train_models/checkpoint-2745/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:41:58,521 >> Model weights saved in train_models/checkpoint-2745/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:41:58,522 >> tokenizer config file saved in train_models/checkpoint-2745/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:41:58,522 >> Special tokens file saved in train_models/checkpoint-2745/special_tokens_map.json\n",
            "{'loss': 2.1422, 'learning_rate': 2e-05, 'epoch': 6.0}                          \n",
            " 60%|███████████████████████▍               | 3294/5490 [14:01<09:03,  4.04it/s][INFO|trainer.py:2868] 2023-05-01 12:44:17,145 >> Saving model checkpoint to train_models/checkpoint-3294\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:44:17,146 >> Configuration saved in train_models/checkpoint-3294/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:44:17,146 >> Configuration saved in train_models/checkpoint-3294/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:44:17,607 >> Model weights saved in train_models/checkpoint-3294/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:44:17,608 >> tokenizer config file saved in train_models/checkpoint-3294/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:44:17,608 >> Special tokens file saved in train_models/checkpoint-3294/special_tokens_map.json\n",
            "{'loss': 2.0308, 'learning_rate': 1.5e-05, 'epoch': 7.0}                        \n",
            " 70%|███████████████████████████▎           | 3843/5490 [16:15<06:34,  4.18it/s][INFO|trainer.py:2868] 2023-05-01 12:46:30,999 >> Saving model checkpoint to train_models/checkpoint-3843\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:46:31,001 >> Configuration saved in train_models/checkpoint-3843/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:46:31,002 >> Configuration saved in train_models/checkpoint-3843/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:46:31,729 >> Model weights saved in train_models/checkpoint-3843/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:46:31,730 >> tokenizer config file saved in train_models/checkpoint-3843/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:46:31,730 >> Special tokens file saved in train_models/checkpoint-3843/special_tokens_map.json\n",
            "{'loss': 1.9473, 'learning_rate': 1e-05, 'epoch': 8.0}                          \n",
            " 80%|███████████████████████████████▏       | 4392/5490 [18:32<04:44,  3.86it/s][INFO|trainer.py:2868] 2023-05-01 12:48:47,388 >> Saving model checkpoint to train_models/checkpoint-4392\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:48:47,389 >> Configuration saved in train_models/checkpoint-4392/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:48:47,389 >> Configuration saved in train_models/checkpoint-4392/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:48:47,840 >> Model weights saved in train_models/checkpoint-4392/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:48:47,840 >> tokenizer config file saved in train_models/checkpoint-4392/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:48:47,840 >> Special tokens file saved in train_models/checkpoint-4392/special_tokens_map.json\n",
            "{'loss': 1.8868, 'learning_rate': 5e-06, 'epoch': 9.0}                          \n",
            " 90%|███████████████████████████████████    | 4941/5490 [20:46<02:12,  4.16it/s][INFO|trainer.py:2868] 2023-05-01 12:51:01,396 >> Saving model checkpoint to train_models/checkpoint-4941\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:51:01,397 >> Configuration saved in train_models/checkpoint-4941/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:51:01,397 >> Configuration saved in train_models/checkpoint-4941/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:51:01,834 >> Model weights saved in train_models/checkpoint-4941/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:51:01,835 >> tokenizer config file saved in train_models/checkpoint-4941/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:51:01,835 >> Special tokens file saved in train_models/checkpoint-4941/special_tokens_map.json\n",
            "{'loss': 1.8525, 'learning_rate': 0.0, 'epoch': 10.0}                           \n",
            "100%|███████████████████████████████████████| 5490/5490 [23:00<00:00,  4.12it/s][INFO|trainer.py:2868] 2023-05-01 12:53:15,894 >> Saving model checkpoint to train_models/checkpoint-5490\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:53:15,896 >> Configuration saved in train_models/checkpoint-5490/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:53:15,897 >> Configuration saved in train_models/checkpoint-5490/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:53:16,577 >> Model weights saved in train_models/checkpoint-5490/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:53:16,578 >> tokenizer config file saved in train_models/checkpoint-5490/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:53:16,578 >> Special tokens file saved in train_models/checkpoint-5490/special_tokens_map.json\n",
            "[INFO|trainer.py:2039] 2023-05-01 12:53:17,525 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1382.3619, 'train_samples_per_second': 3.971, 'train_steps_per_second': 3.971, 'train_loss': 2.33636224465292, 'epoch': 10.0}\n",
            "100%|███████████████████████████████████████| 5490/5490 [23:02<00:00,  3.97it/s]\n",
            "[INFO|trainer.py:2868] 2023-05-01 12:53:17,527 >> Saving model checkpoint to train_models\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:53:17,527 >> Configuration saved in train_models/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:53:17,528 >> Configuration saved in train_models/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:53:18,000 >> Model weights saved in train_models/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:53:18,002 >> tokenizer config file saved in train_models/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:53:18,002 >> Special tokens file saved in train_models/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  train_loss               =     2.3364\n",
            "  train_runtime            = 0:23:02.36\n",
            "  train_samples            =        549\n",
            "  train_samples_per_second =      3.971\n",
            "  train_steps_per_second   =      3.971\n",
            "[INFO|modelcard.py:451] 2023-05-01 12:53:18,408 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
            "05/01/2023 12:53:21 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/01/2023 12:53:21 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=train_models/runs/May01_12-53-21_andreib-Legion-5-Pro-16ACH6H,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=epoch,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=10.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=train_models,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=train_models,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=None,\n",
            "seed=43,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "05/01/2023 12:53:21 - INFO - datasets.builder - Using custom data configuration default-3e166d1c2d527ed4\n",
            "05/01/2023 12:53:21 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 12:53:21 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 12:53:21 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 12:53:21 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 12:53:21 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 177.71it/s]\n",
            "05/01/2023 12:53:22 - INFO - datasets.builder - Using custom data configuration default-3e166d1c2d527ed4\n",
            "05/01/2023 12:53:22 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 12:53:22 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 12:53:22 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 12:53:22 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 12:53:22 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 12:53:22 - INFO - datasets.builder - Using custom data configuration default-3e166d1c2d527ed4\n",
            "05/01/2023 12:53:22 - INFO - datasets.info - Loading Dataset Infos from /home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/datasets/packaged_modules/json\n",
            "05/01/2023 12:53:22 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "05/01/2023 12:53:22 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "05/01/2023 12:53:22 - WARNING - datasets.builder - Found cached dataset json (/home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
            "05/01/2023 12:53:22 - INFO - datasets.info - Loading Dataset info from /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 12:53:22,777 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 12:53:22,777 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:502] 2023-05-01 12:53:22,902 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 12:53:23,033 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 12:53:23,033 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:53:23,294 >> loading file vocab.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:53:23,294 >> loading file merges.txt from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:53:23,294 >> loading file tokenizer.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:53:23,294 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:53:23,294 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1809] 2023-05-01 12:53:23,295 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:668] 2023-05-01 12:53:23,295 >> loading configuration file config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\n",
            "[INFO|configuration_utils.py:720] 2023-05-01 12:53:23,295 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.28.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:2534] 2023-05-01 12:53:23,342 >> loading weights file pytorch_model.bin from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/pytorch_model.bin\n",
            "[INFO|configuration_utils.py:575] 2023-05-01 12:53:23,569 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:3190] 2023-05-01 12:53:24,500 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:3198] 2023-05-01 12:53:24,500 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "[INFO|configuration_utils.py:537] 2023-05-01 12:53:24,621 >> loading configuration file generation_config.json from cache at /home/andreib/.cache/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/generation_config.json\n",
            "[INFO|configuration_utils.py:575] 2023-05-01 12:53:24,622 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.28.1\"\n",
            "}\n",
            "\n",
            "05/01/2023 12:53:24 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-cf508a405cade77c.arrow\n",
            "05/01/2023 12:53:24 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-214f26defabb7fc1.arrow\n",
            "05/01/2023 12:53:24 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-e4b2e9b2d959e943.arrow\n",
            "05/01/2023 12:53:24 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/andreib/.cache/huggingface/datasets/json/default-3e166d1c2d527ed4/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/cache-7855d5e3d79f83cc.arrow\n",
            "/home/andreib/miniconda3/envs/bias_measure/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1769] 2023-05-01 12:53:25,534 >> ***** Running training *****\n",
            "[INFO|trainer.py:1770] 2023-05-01 12:53:25,534 >>   Num examples = 549\n",
            "[INFO|trainer.py:1771] 2023-05-01 12:53:25,534 >>   Num Epochs = 10\n",
            "[INFO|trainer.py:1772] 2023-05-01 12:53:25,534 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1773] 2023-05-01 12:53:25,534 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1774] 2023-05-01 12:53:25,534 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1775] 2023-05-01 12:53:25,535 >>   Total optimization steps = 5,490\n",
            "[INFO|trainer.py:1776] 2023-05-01 12:53:25,535 >>   Number of trainable parameters = 124,439,808\n",
            "{'loss': 3.2519, 'learning_rate': 4.5e-05, 'epoch': 1.0}                        \n",
            " 10%|████                                    | 549/5490 [02:13<19:56,  4.13it/s][INFO|trainer.py:2868] 2023-05-01 12:55:39,117 >> Saving model checkpoint to train_models/checkpoint-549\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:55:39,119 >> Configuration saved in train_models/checkpoint-549/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:55:39,120 >> Configuration saved in train_models/checkpoint-549/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:55:39,848 >> Model weights saved in train_models/checkpoint-549/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:55:39,848 >> tokenizer config file saved in train_models/checkpoint-549/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:55:39,849 >> Special tokens file saved in train_models/checkpoint-549/special_tokens_map.json\n",
            "{'loss': 2.8858, 'learning_rate': 4e-05, 'epoch': 2.0}                          \n",
            " 20%|███████▊                               | 1098/5490 [04:29<17:50,  4.10it/s][INFO|trainer.py:2868] 2023-05-01 12:57:55,467 >> Saving model checkpoint to train_models/checkpoint-1098\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 12:57:55,468 >> Configuration saved in train_models/checkpoint-1098/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 12:57:55,469 >> Configuration saved in train_models/checkpoint-1098/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 12:57:56,228 >> Model weights saved in train_models/checkpoint-1098/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 12:57:56,228 >> tokenizer config file saved in train_models/checkpoint-1098/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 12:57:56,228 >> Special tokens file saved in train_models/checkpoint-1098/special_tokens_map.json\n",
            "{'loss': 2.6504, 'learning_rate': 3.5e-05, 'epoch': 3.0}                        \n",
            " 30%|███████████▋                           | 1647/5490 [06:45<15:38,  4.10it/s][INFO|trainer.py:2868] 2023-05-01 13:00:11,065 >> Saving model checkpoint to train_models/checkpoint-1647\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 13:00:11,067 >> Configuration saved in train_models/checkpoint-1647/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 13:00:11,067 >> Configuration saved in train_models/checkpoint-1647/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 13:00:11,798 >> Model weights saved in train_models/checkpoint-1647/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 13:00:11,799 >> tokenizer config file saved in train_models/checkpoint-1647/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 13:00:11,799 >> Special tokens file saved in train_models/checkpoint-1647/special_tokens_map.json\n",
            "{'loss': 2.4529, 'learning_rate': 3e-05, 'epoch': 4.0}                          \n",
            " 40%|███████████████▌                       | 2196/5490 [09:00<13:14,  4.15it/s][INFO|trainer.py:2868] 2023-05-01 13:02:25,928 >> Saving model checkpoint to train_models/checkpoint-2196\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 13:02:25,929 >> Configuration saved in train_models/checkpoint-2196/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 13:02:25,930 >> Configuration saved in train_models/checkpoint-2196/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 13:02:26,650 >> Model weights saved in train_models/checkpoint-2196/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 13:02:26,651 >> tokenizer config file saved in train_models/checkpoint-2196/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 13:02:26,651 >> Special tokens file saved in train_models/checkpoint-2196/special_tokens_map.json\n",
            "{'loss': 2.2859, 'learning_rate': 2.5e-05, 'epoch': 5.0}                        \n",
            " 50%|███████████████████▌                   | 2745/5490 [11:15<11:04,  4.13it/s][INFO|trainer.py:2868] 2023-05-01 13:04:41,285 >> Saving model checkpoint to train_models/checkpoint-2745\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 13:04:41,287 >> Configuration saved in train_models/checkpoint-2745/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 13:04:41,288 >> Configuration saved in train_models/checkpoint-2745/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 13:04:42,003 >> Model weights saved in train_models/checkpoint-2745/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 13:04:42,004 >> tokenizer config file saved in train_models/checkpoint-2745/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 13:04:42,004 >> Special tokens file saved in train_models/checkpoint-2745/special_tokens_map.json\n",
            "{'loss': 2.148, 'learning_rate': 2e-05, 'epoch': 6.0}                           \n",
            " 60%|███████████████████████▍               | 3294/5490 [13:31<08:53,  4.11it/s][INFO|trainer.py:2868] 2023-05-01 13:06:56,776 >> Saving model checkpoint to train_models/checkpoint-3294\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 13:06:56,777 >> Configuration saved in train_models/checkpoint-3294/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 13:06:56,778 >> Configuration saved in train_models/checkpoint-3294/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 13:06:57,346 >> Model weights saved in train_models/checkpoint-3294/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 13:06:57,347 >> tokenizer config file saved in train_models/checkpoint-3294/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 13:06:57,347 >> Special tokens file saved in train_models/checkpoint-3294/special_tokens_map.json\n",
            "{'loss': 2.0368, 'learning_rate': 1.5e-05, 'epoch': 7.0}                        \n",
            " 70%|███████████████████████████▎           | 3843/5490 [15:51<07:00,  3.91it/s][INFO|trainer.py:2868] 2023-05-01 13:09:16,815 >> Saving model checkpoint to train_models/checkpoint-3843\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 13:09:16,816 >> Configuration saved in train_models/checkpoint-3843/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 13:09:16,816 >> Configuration saved in train_models/checkpoint-3843/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 13:09:17,303 >> Model weights saved in train_models/checkpoint-3843/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 13:09:17,303 >> tokenizer config file saved in train_models/checkpoint-3843/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 13:09:17,304 >> Special tokens file saved in train_models/checkpoint-3843/special_tokens_map.json\n",
            "{'loss': 1.9544, 'learning_rate': 1e-05, 'epoch': 8.0}                          \n",
            " 80%|███████████████████████████████▏       | 4392/5490 [18:09<04:48,  3.81it/s][INFO|trainer.py:2868] 2023-05-01 13:11:35,334 >> Saving model checkpoint to train_models/checkpoint-4392\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 13:11:35,334 >> Configuration saved in train_models/checkpoint-4392/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 13:11:35,334 >> Configuration saved in train_models/checkpoint-4392/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 13:11:35,834 >> Model weights saved in train_models/checkpoint-4392/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 13:11:35,835 >> tokenizer config file saved in train_models/checkpoint-4392/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 13:11:35,835 >> Special tokens file saved in train_models/checkpoint-4392/special_tokens_map.json\n",
            "{'loss': 1.8932, 'learning_rate': 5e-06, 'epoch': 9.0}                          \n",
            " 90%|███████████████████████████████████    | 4941/5490 [20:34<02:18,  3.98it/s][INFO|trainer.py:2868] 2023-05-01 13:14:00,368 >> Saving model checkpoint to train_models/checkpoint-4941\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 13:14:00,369 >> Configuration saved in train_models/checkpoint-4941/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 13:14:00,369 >> Configuration saved in train_models/checkpoint-4941/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 13:14:00,846 >> Model weights saved in train_models/checkpoint-4941/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 13:14:00,847 >> tokenizer config file saved in train_models/checkpoint-4941/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 13:14:00,847 >> Special tokens file saved in train_models/checkpoint-4941/special_tokens_map.json\n",
            "{'loss': 1.8579, 'learning_rate': 0.0, 'epoch': 10.0}                           \n",
            "100%|███████████████████████████████████████| 5490/5490 [22:56<00:00,  3.94it/s][INFO|trainer.py:2868] 2023-05-01 13:16:21,568 >> Saving model checkpoint to train_models/checkpoint-5490\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 13:16:21,576 >> Configuration saved in train_models/checkpoint-5490/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 13:16:21,576 >> Configuration saved in train_models/checkpoint-5490/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 13:16:22,047 >> Model weights saved in train_models/checkpoint-5490/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 13:16:22,047 >> tokenizer config file saved in train_models/checkpoint-5490/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 13:16:22,047 >> Special tokens file saved in train_models/checkpoint-5490/special_tokens_map.json\n",
            "[INFO|trainer.py:2039] 2023-05-01 13:16:23,053 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1377.518, 'train_samples_per_second': 3.985, 'train_steps_per_second': 3.985, 'train_loss': 2.341720141912853, 'epoch': 10.0}\n",
            "100%|███████████████████████████████████████| 5490/5490 [22:57<00:00,  3.99it/s]\n",
            "[INFO|trainer.py:2868] 2023-05-01 13:16:23,054 >> Saving model checkpoint to train_models\n",
            "[INFO|configuration_utils.py:457] 2023-05-01 13:16:23,055 >> Configuration saved in train_models/config.json\n",
            "[INFO|configuration_utils.py:362] 2023-05-01 13:16:23,055 >> Configuration saved in train_models/generation_config.json\n",
            "[INFO|modeling_utils.py:1847] 2023-05-01 13:16:23,531 >> Model weights saved in train_models/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2171] 2023-05-01 13:16:23,531 >> tokenizer config file saved in train_models/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2178] 2023-05-01 13:16:23,531 >> Special tokens file saved in train_models/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  train_loss               =     2.3417\n",
            "  train_runtime            = 0:22:57.51\n",
            "  train_samples            =        549\n",
            "  train_samples_per_second =      3.985\n",
            "  train_steps_per_second   =      3.985\n",
            "[INFO|modelcard.py:451] 2023-05-01 13:16:23,886 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
          ]
        }
      ],
      "source": [
        "!bash train_models.sh supportive"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "bias_measure",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "002e1b7b24a541aabc852e564b675aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2c5af8a7391458d90028e597c7bc8f9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f16160c6eb4472fbcd51043e3800b35",
            "value": 1
          }
        },
        "073f3be169c14e70800cb4b87751bb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_338a7e4f41bb4690b662dc3fd30d7ebe",
            "placeholder": "​",
            "style": "IPY_MODEL_a223a0e5214e4bcb8ad92b72a2918500",
            "value": "Filter: 100%"
          }
        },
        "0ca441fdd04744c4a30897c29912d057": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e4a4e8d50434200b6cd18b7aa5820de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f038ce3fd0d4dbcb04aa4ddb59b7fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "105e32bb12f841999ffbfce4d8233104": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca441fdd04744c4a30897c29912d057",
            "placeholder": "​",
            "style": "IPY_MODEL_9d8b72763b604fcdab0e1a277292b4ea",
            "value": "Creating json from Arrow format: 100%"
          }
        },
        "1266ea5009bd4c1e84ed3fe7f8592002": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18a3a1901b4f4325978a9270bb47f233": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1d220747cf7a40459f14ec76c4ae6f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5703ca92127d422bb002cc9f75509f93",
            "placeholder": "​",
            "style": "IPY_MODEL_6a2c5f7d9f564ea194e47488d1156be2",
            "value": "Downloading data files: 100%"
          }
        },
        "1f2b74ec06a541fdbb189bbedf5b01be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "229a93cff19942fe89c01d3dc99d517c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78c68ba42b134b85979dde19e69c4468",
            "placeholder": "​",
            "style": "IPY_MODEL_698d5a19f42f4dde85b99cfa7493152d",
            "value": " 135000/135556 [00:14&lt;00:00, 11645.05 examples/s]"
          }
        },
        "2922199917e542c6abdadbfd6d4a42ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29a34161d21f4890ac57133b47c7e684": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ba67b17fc4942dda20a3d5ee38aa9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f72d1114716e4ad1a592c7cbe62048d7",
            "placeholder": "​",
            "style": "IPY_MODEL_c4ed1d90c26d44d3aa7bea466ef6d11c",
            "value": "Extracting data files: 100%"
          }
        },
        "2ca80599a6c1441998d01c3472d14da6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d19ede889f64535a4263791187ef859": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ba67b17fc4942dda20a3d5ee38aa9e6",
              "IPY_MODEL_e203ac4ea3e34411a178f5f7f68203b4",
              "IPY_MODEL_48a63987154e4a59b1f3f8d747044865"
            ],
            "layout": "IPY_MODEL_3059654746274ed2abd9c34989037e9a"
          }
        },
        "2e8691c91b1e4f079b93fcc29ff15d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9b7db3a2c3043adb01005db2a0bda57",
            "max": 48352,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7004ada81654ca69fb126d70b5de37a",
            "value": 48352
          }
        },
        "3001a417a3ec4531aff85da5be041b7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3059654746274ed2abd9c34989037e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "338a7e4f41bb4690b662dc3fd30d7ebe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a3bc785dfa497cbb15585bad5c5df9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "389ae4f54a2a40558df017945f7ffb8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a3470f3c47f471299be17a566e4bebe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d16f1796bec4646817748c4f6ced833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67417eda9a724c46a5644fbdb13f5351",
              "IPY_MODEL_8857202e6e4d4630a9d1cfb4860e2b57",
              "IPY_MODEL_a012e717318f452fbb4c613f81d480a6"
            ],
            "layout": "IPY_MODEL_db0b2e2cfd4a42b8946de1cb971f575b"
          }
        },
        "40cf5bd5dff5453db48821cebcb3b565": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f15cb44d21834898b5c5909343178d2f",
              "IPY_MODEL_98e6f7ffd9db46aaa87e34e59f5786cf",
              "IPY_MODEL_bd592bc8a8cb4656bd75cb6cdb035e49"
            ],
            "layout": "IPY_MODEL_4a4346ec55344027b2d8bd8033ac5f2a"
          }
        },
        "4328f1fd44e04ed08d7229ba4cddffd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a373b6468454960b2c12b14e5f1e2d7",
            "placeholder": "​",
            "style": "IPY_MODEL_d7f5c54c365c41abb40fc9f08febbf37",
            "value": " 16/16 [00:03&lt;00:00,  4.86ba/s]"
          }
        },
        "4781905385464ee98d957e4210d3e1ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48a63987154e4a59b1f3f8d747044865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f2b74ec06a541fdbb189bbedf5b01be",
            "placeholder": "​",
            "style": "IPY_MODEL_d177d3b709414ca48e7df0d96efffdd7",
            "value": " 1/1 [00:00&lt;00:00, 51.12it/s]"
          }
        },
        "4a4346ec55344027b2d8bd8033ac5f2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a5f6effe59b470ea10aec5a5a47db7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21168d2665d42b7a25814e013d766f8",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2922199917e542c6abdadbfd6d4a42ac",
            "value": 16
          }
        },
        "56683fa9b3c0411abe351c00e58bd30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5703ca92127d422bb002cc9f75509f93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bfeb895e0eb4a4aa73d4ecf429ab604": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5c2190a83d2f438787f4dae24c172d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5da061ef0d2949e494193895ca009950": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ea241d2a111487abe7fe34f8731817d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ea9cf668813400f86d519539dd020f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61bc5257f6564ce4991110540306dcd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36a3bc785dfa497cbb15585bad5c5df9",
            "placeholder": "​",
            "style": "IPY_MODEL_c4d15b4387a949678ad51ec0f314b329",
            "value": " 135556/0 [00:00&lt;00:00, 305353.15 examples/s]"
          }
        },
        "67370c9b64444c46877584825c6f982d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67417eda9a724c46a5644fbdb13f5351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42b9e0cf8054f18933240dcfa3dea21",
            "placeholder": "​",
            "style": "IPY_MODEL_adb4836c7d7c4260aff58099abea73eb",
            "value": "Downloading readme: 100%"
          }
        },
        "698d5a19f42f4dde85b99cfa7493152d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a2c5f7d9f564ea194e47488d1156be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a373b6468454960b2c12b14e5f1e2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70d03013efbe41df8a656f310406dc5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72623227cb1644da947f8848763b9098": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72da34bb5795473aa1331e1621cb6a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92494b41d9ad440ba9213cee6c60b07a",
              "IPY_MODEL_f21baa9638b94367bbfaa7b974901d6c",
              "IPY_MODEL_868f9c715bcb40729014de10e4a7b2ec"
            ],
            "layout": "IPY_MODEL_9a44f7b88b184707b88057edee1861ea"
          }
        },
        "78c68ba42b134b85979dde19e69c4468": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78dc35837b8548ca91c33b4c99a6dfb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b29305448714f86927b3a392c4d2cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7df307db34c445e88a4206707ecd2a23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f0375ecf2364c1c88eed4bb32f9f2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0039c70c8aa4c878899e75901999b77",
            "placeholder": "​",
            "style": "IPY_MODEL_fc15a538ecd74af691253b5e01a8ab33",
            "value": "Generating train split: "
          }
        },
        "81f1e3bc51374593920d69db26024fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c17cafd4a69b43f18279553cb6c458d6",
            "placeholder": "​",
            "style": "IPY_MODEL_f2b5e1bc173047f09f77dfc0fba8313c",
            "value": " 48352/48352 [00:23&lt;00:00, 2552.67 examples/s]"
          }
        },
        "82c9bf90d18a420a8d292f338f7956ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8457f53f4a7743a0aa4b8329302f252d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89fce2fcbdd442f5bfc70c09044cc1ff",
            "placeholder": "​",
            "style": "IPY_MODEL_70d03013efbe41df8a656f310406dc5a",
            "value": " 22/22 [00:04&lt;00:00,  4.59ba/s]"
          }
        },
        "868f9c715bcb40729014de10e4a7b2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72623227cb1644da947f8848763b9098",
            "placeholder": "​",
            "style": "IPY_MODEL_1266ea5009bd4c1e84ed3fe7f8592002",
            "value": " 48352/48352 [00:19&lt;00:00, 2524.09 examples/s]"
          }
        },
        "870456e94e974d97ae39a18184d5695b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd99f77d366e40508f48da474995f27e",
              "IPY_MODEL_98c06b7a8d47425baeb7ce8fe1199f82",
              "IPY_MODEL_8457f53f4a7743a0aa4b8329302f252d"
            ],
            "layout": "IPY_MODEL_b52af05e0bd146c0839a15e4729e165f"
          }
        },
        "8857202e6e4d4630a9d1cfb4860e2b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd4e1e6b4f1e46f1807a4b338ba2565a",
            "max": 4028,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c125a61a7a1445488c78dffa8acb47cf",
            "value": 4028
          }
        },
        "89fce2fcbdd442f5bfc70c09044cc1ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e03d6ac95ef401ab560e376fd3467a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8efd998eba084dc9965de646ee294113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e03d6ac95ef401ab560e376fd3467a0",
            "placeholder": "​",
            "style": "IPY_MODEL_d049e7763a74459a927ad5afd12e3709",
            "value": " 14.1M/14.1M [00:00&lt;00:00, 32.9MB/s]"
          }
        },
        "8f16160c6eb4472fbcd51043e3800b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92494b41d9ad440ba9213cee6c60b07a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebeee8610da74e76824fd424f8ca267b",
            "placeholder": "​",
            "style": "IPY_MODEL_389ae4f54a2a40558df017945f7ffb8b",
            "value": "Filter: 100%"
          }
        },
        "987d759916294789a1dc7e888d0a9060": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c06b7a8d47425baeb7ce8fe1199f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b39ab02ef733474692d4b04cf93abb08",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e4a4e8d50434200b6cd18b7aa5820de",
            "value": 22
          }
        },
        "98e6f7ffd9db46aaa87e34e59f5786cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4781905385464ee98d957e4210d3e1ce",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ccd2e8e3ced4a67ae6803d6d9caac0e",
            "value": 1
          }
        },
        "9a44f7b88b184707b88057edee1861ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "9ccd2e8e3ced4a67ae6803d6d9caac0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d8b72763b604fcdab0e1a277292b4ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e3d732e91a44db8a0d884a6d1f99139": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a012e717318f452fbb4c613f81d480a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3d279e6c3c245ebae1397decb9281ad",
            "placeholder": "​",
            "style": "IPY_MODEL_e75c59889e4f467595781640aa0b575a",
            "value": " 4.03k/4.03k [00:00&lt;00:00, 287kB/s]"
          }
        },
        "a223a0e5214e4bcb8ad92b72a2918500": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6a409510da242a1b7f135fd81e17f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a792ff96ada64f3eae2a82b073657cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7df307db34c445e88a4206707ecd2a23",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c2190a83d2f438787f4dae24c172d9c",
            "value": 1
          }
        },
        "a8fffb769de846e29919882ad05e69c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e3d732e91a44db8a0d884a6d1f99139",
            "placeholder": "​",
            "style": "IPY_MODEL_ed5d2aec689c49c59222ddbf4cfc2f83",
            "value": "Filter: 100%"
          }
        },
        "a9a620c2f4b54e80b4d5c7cb72abf976": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8fffb769de846e29919882ad05e69c4",
              "IPY_MODEL_e02cf20e55ab45389bde04db96c31b2a",
              "IPY_MODEL_229a93cff19942fe89c01d3dc99d517c"
            ],
            "layout": "IPY_MODEL_18a3a1901b4f4325978a9270bb47f233"
          }
        },
        "ac1eab1a90e14c11a3a710d07192f8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_105e32bb12f841999ffbfce4d8233104",
              "IPY_MODEL_4a5f6effe59b470ea10aec5a5a47db7d",
              "IPY_MODEL_4328f1fd44e04ed08d7229ba4cddffd0"
            ],
            "layout": "IPY_MODEL_78dc35837b8548ca91c33b4c99a6dfb9"
          }
        },
        "adb4836c7d7c4260aff58099abea73eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b322ad7df7b545b6a2666075421d3cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b39ab02ef733474692d4b04cf93abb08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42b9e0cf8054f18933240dcfa3dea21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b52af05e0bd146c0839a15e4729e165f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7004ada81654ca69fb126d70b5de37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9b7db3a2c3043adb01005db2a0bda57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba3dc6e38c5a4476a78849bc68ae32bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f0375ecf2364c1c88eed4bb32f9f2fc",
              "IPY_MODEL_002e1b7b24a541aabc852e564b675aa8",
              "IPY_MODEL_61bc5257f6564ce4991110540306dcd3"
            ],
            "layout": "IPY_MODEL_5bfeb895e0eb4a4aa73d4ecf429ab604"
          }
        },
        "bbf2040223e846e3815d685ab37fed54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_073f3be169c14e70800cb4b87751bb66",
              "IPY_MODEL_2e8691c91b1e4f079b93fcc29ff15d19",
              "IPY_MODEL_81f1e3bc51374593920d69db26024fc3"
            ],
            "layout": "IPY_MODEL_ce58a391eaea470ebb8123a9461179e8"
          }
        },
        "bd4e1e6b4f1e46f1807a4b338ba2565a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd592bc8a8cb4656bd75cb6cdb035e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf0411676f014c1cadea42e0d3bcc9cf",
            "placeholder": "​",
            "style": "IPY_MODEL_29a34161d21f4890ac57133b47c7e684",
            "value": " 1/1 [00:00&lt;00:00, 14.83it/s]"
          }
        },
        "be0605c3e045431aa489f159bbc29733": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0039c70c8aa4c878899e75901999b77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c125a61a7a1445488c78dffa8acb47cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c17cafd4a69b43f18279553cb6c458d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d15b4387a949678ad51ec0f314b329": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4ed1d90c26d44d3aa7bea466ef6d11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6a206b64478449b8736a6fa6ca7db38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd99f77d366e40508f48da474995f27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_987d759916294789a1dc7e888d0a9060",
            "placeholder": "​",
            "style": "IPY_MODEL_82c9bf90d18a420a8d292f338f7956ff",
            "value": "Creating json from Arrow format: 100%"
          }
        },
        "ce58a391eaea470ebb8123a9461179e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "cf0411676f014c1cadea42e0d3bcc9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d049e7763a74459a927ad5afd12e3709": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d15d3e5175b74f60ad51350698c5199f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff7e10ade6be4aa2973e21fea784a6a1",
            "placeholder": "​",
            "style": "IPY_MODEL_56683fa9b3c0411abe351c00e58bd30b",
            "value": " 1/1 [00:01&lt;00:00,  1.20s/it]"
          }
        },
        "d177d3b709414ca48e7df0d96efffdd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3f543e1ec004e47adfaa8a170e0dbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d220747cf7a40459f14ec76c4ae6f07",
              "IPY_MODEL_a792ff96ada64f3eae2a82b073657cbe",
              "IPY_MODEL_d15d3e5175b74f60ad51350698c5199f"
            ],
            "layout": "IPY_MODEL_2ca80599a6c1441998d01c3472d14da6"
          }
        },
        "d7f5c54c365c41abb40fc9f08febbf37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db0b2e2cfd4a42b8946de1cb971f575b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc3dd07ca3954d61a773b57ec6f41fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc30346c2fed43409abf9f2f7e87a2d0",
              "IPY_MODEL_f4ed0b54a9064e8e80ad7e5d8c909f68",
              "IPY_MODEL_8efd998eba084dc9965de646ee294113"
            ],
            "layout": "IPY_MODEL_c6a206b64478449b8736a6fa6ca7db38"
          }
        },
        "df017358258740ada5f1cc6c834df122": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02cf20e55ab45389bde04db96c31b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b322ad7df7b545b6a2666075421d3cb3",
            "max": 135556,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be0605c3e045431aa489f159bbc29733",
            "value": 135556
          }
        },
        "e203ac4ea3e34411a178f5f7f68203b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3001a417a3ec4531aff85da5be041b7d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b29305448714f86927b3a392c4d2cbf",
            "value": 1
          }
        },
        "e21168d2665d42b7a25814e013d766f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d279e6c3c245ebae1397decb9281ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e75c59889e4f467595781640aa0b575a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebeee8610da74e76824fd424f8ca267b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed5d2aec689c49c59222ddbf4cfc2f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f15cb44d21834898b5c5909343178d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a3470f3c47f471299be17a566e4bebe",
            "placeholder": "​",
            "style": "IPY_MODEL_a6a409510da242a1b7f135fd81e17f37",
            "value": "100%"
          }
        },
        "f21baa9638b94367bbfaa7b974901d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f038ce3fd0d4dbcb04aa4ddb59b7fd9",
            "max": 48352,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ea241d2a111487abe7fe34f8731817d",
            "value": 48352
          }
        },
        "f2b5e1bc173047f09f77dfc0fba8313c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2c5af8a7391458d90028e597c7bc8f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f4ed0b54a9064e8e80ad7e5d8c909f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df017358258740ada5f1cc6c834df122",
            "max": 14123673,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67370c9b64444c46877584825c6f982d",
            "value": 14123673
          }
        },
        "f72d1114716e4ad1a592c7cbe62048d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc15a538ecd74af691253b5e01a8ab33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc30346c2fed43409abf9f2f7e87a2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ea9cf668813400f86d519539dd020f3",
            "placeholder": "​",
            "style": "IPY_MODEL_5da061ef0d2949e494193895ca009950",
            "value": "Downloading data: 100%"
          }
        },
        "ff7e10ade6be4aa2973e21fea784a6a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
